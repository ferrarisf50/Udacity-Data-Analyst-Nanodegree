{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1449431, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "import ast\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "train=pd.read_csv(r\"route_coord.csv\")\n",
    "train['index1'] = train.index\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_coord(idx,x):\n",
    "    \n",
    "\n",
    "    #global coordinate_count\n",
    "    x1=ast.literal_eval(x)\n",
    "    x2=[ tuple(j) for j in x1]\n",
    "    x3=Counter(x2)\n",
    "    #coordinate_count=coordinate_count+x3\n",
    "    if idx % 10000==0:\n",
    "        print(str(idx)+\" done\")\n",
    "\n",
    "    return x3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000 done\n",
      "510000 done\n",
      "520000 done\n",
      "530000 done\n",
      "540000 done\n",
      "pool done!\n",
      "550000 done\n",
      "560000 done\n",
      "570000 done\n",
      "580000 done\n",
      "590000 done\n",
      "pool done!\n",
      "600000 done\n",
      "610000 done\n",
      "620000 done\n",
      "630000 done\n",
      "640000 done\n",
      "pool done!\n",
      "650000 done\n",
      "660000 done\n",
      "670000 done\n",
      "680000 done\n",
      "690000 done\n",
      "pool done!\n",
      "700000 done\n",
      "710000 done\n",
      "720000 done\n",
      "730000 done\n",
      "740000 done\n",
      "pool done!\n",
      "750000 done\n",
      "760000 done\n",
      "770000 done\n",
      "780000 done\n",
      "790000 done\n",
      "pool done!\n",
      "800000 done\n",
      "810000 done\n",
      "820000 done\n",
      "830000 done\n",
      "840000 done\n",
      "pool done!\n",
      "850000 done\n",
      "860000 done\n",
      "870000 done\n",
      "880000 done\n",
      "890000 done\n",
      "pool done!\n",
      "900000 done\n",
      "910000 done\n",
      "920000 done\n",
      "930000 done\n",
      "940000 done\n",
      "pool done!\n",
      "950000 done\n",
      "960000 done\n",
      "970000 done\n",
      "980000 done\n",
      "990000 done\n",
      "pool done!\n",
      "1000000 done\n",
      "1010000 done\n",
      "1020000 done\n",
      "1030000 done\n",
      "1040000 done\n",
      "pool done!\n",
      "1050000 done\n",
      "1060000 done\n",
      "1070000 done\n",
      "1080000 done\n",
      "1090000 done\n",
      "pool done!\n",
      "1100000 done\n",
      "1110000 done\n",
      "1120000 done\n",
      "1130000 done\n",
      "1140000 done\n",
      "pool done!\n",
      "1150000 done\n",
      "1160000 done\n",
      "1170000 done\n",
      "1180000 done\n",
      "1190000 done\n",
      "pool done!\n",
      "1200000 done\n",
      "1210000 done\n",
      "1220000 done\n",
      "1230000 done\n",
      "1240000 done\n",
      "pool done!\n",
      "1250000 done\n",
      "1260000 done\n",
      "1270000 done\n",
      "1280000 done\n",
      "1290000 done\n",
      "pool done!\n",
      "1300000 done\n",
      "1310000 done\n",
      "1320000 done\n",
      "1330000 done\n",
      "1340000 done\n",
      "pool done!\n",
      "1350000 done\n",
      "1360000 done\n",
      "1370000 done\n",
      "1380000 done\n",
      "1390000 done\n",
      "pool done!\n",
      "1400000 done\n",
      "1410000 done\n",
      "1420000 done\n",
      "1430000 done\n",
      "1440000 done\n",
      "pool done!\n"
     ]
    }
   ],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    #coordinate_count=Counter([])\n",
    "\n",
    "    filenum=0\n",
    "    \n",
    "    for train1 in chunker(train,50000):\n",
    "        if filenum >=10:\n",
    "            coordinate_count=Counter([])\n",
    "\n",
    "            def sum_counter(x):\n",
    "                global coordinate_count\n",
    "                coordinate_count+=x\n",
    "                \n",
    "            url1=train1[['index1','route_cooridnates']].values.tolist()\n",
    "            urls=[ tuple(i) for i in url1]\n",
    "            \n",
    "            pool = multiprocessing.Pool(100)  # 4核CPU,该语句的作用可同时并行 4 个进程的进程池\n",
    "            for x in urls:\n",
    "            \n",
    "                pool.apply_async(count_coord,x,callback=sum_counter)\n",
    "                \n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            with open('Counter'+str(filenum)+'.pickle', 'wb') as handle:\n",
    "                pickle.dump(coordinate_count, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            print(\"pool done!\")\n",
    "            \n",
    "            #break\n",
    "\n",
    "\n",
    "\n",
    "        filenum+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_count_df=pd.DataFrame(list(coordinate_count.items()), columns=['coordinates', 'count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_count_df.to_csv(\"route_coord_count.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coordinate_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_count_df.sort_values('count',ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Counter0.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "with open('Counter1.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
